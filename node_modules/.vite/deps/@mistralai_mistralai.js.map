{
  "version": 3,
  "sources": ["../../@mistralai/mistralai/src/client.js"],
  "sourcesContent": ["let isNode = false;\n\nconst VERSION = '0.0.3';\nconst RETRY_STATUS_CODES = [429, 500, 502, 503, 504];\nconst ENDPOINT = 'https://api.mistral.ai';\n\n/**\n * Initialize fetch\n * @return {Promise<void>}\n */\nasync function initializeFetch() {\n  if (typeof window === 'undefined' ||\n    typeof globalThis.fetch === 'undefined') {\n    const nodeFetch = await import('node-fetch');\n    fetch = nodeFetch.default;\n    isNode = true;\n  } else {\n    fetch = globalThis.fetch;\n  }\n}\n\ninitializeFetch();\n\n/**\n * MistralAPIError\n * @return {MistralAPIError}\n * @extends {Error}\n */\nclass MistralAPIError extends Error {\n  /**\n   * A simple error class for Mistral API errors\n   * @param {*} message\n   */\n  constructor(message) {\n    super(message);\n    this.name = 'MistralAPIError';\n  }\n};\n\n/**\n * MistralClient\n * @return {MistralClient}\n */\nclass MistralClient {\n  /**\n   * A simple and lightweight client for the Mistral API\n   * @param {*} apiKey can be set as an environment variable MISTRAL_API_KEY,\n   * or provided in this parameter\n   * @param {*} endpoint defaults to https://api.mistral.ai\n   * @param {*} maxRetries defaults to 5\n   * @param {*} timeout defaults to 120 seconds\n   */\n  constructor(\n    apiKey = process.env.MISTRAL_API_KEY,\n    endpoint = ENDPOINT,\n    maxRetries = 5,\n    timeout = 120,\n  ) {\n    this.endpoint = endpoint;\n    this.apiKey = apiKey;\n\n    this.maxRetries = maxRetries;\n    this.timeout = timeout;\n  }\n\n  /**\n   *\n   * @param {*} method\n   * @param {*} path\n   * @param {*} request\n   * @return {Promise<*>}\n   */\n  _request = async function(method, path, request) {\n    const url = `${this.endpoint}/${path}`;\n    const options = {\n      method: method,\n      headers: {\n        'User-Agent': `mistral-client-js/${VERSION}`,\n        'Accept': request?.stream ? 'text/event-stream' : 'application/json',\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${this.apiKey}`,\n      },\n      body: method !== 'get' ? JSON.stringify(request) : null,\n      timeout: this.timeout * 1000,\n    };\n\n    for (let attempts = 0; attempts < this.maxRetries; attempts++) {\n      try {\n        const response = await fetch(url, options);\n\n        if (response.ok) {\n          if (request?.stream) {\n            if (isNode) {\n              return response.body;\n            } else {\n              const reader = response.body.getReader();\n              // Chrome does not support async iterators yet, so polyfill it\n              const asyncIterator = async function* () {\n                try {\n                  while (true) {\n                    // Read from the stream\n                    const {done, value} = await reader.read();\n                    // Exit if we're done\n                    if (done) return;\n                    // Else yield the chunk\n                    yield value;\n                  }\n                } finally {\n                  reader.releaseLock();\n                }\n              };\n\n              return asyncIterator();\n            }\n          }\n          return await response.json();\n        } else if (RETRY_STATUS_CODES.includes(response.status)) {\n          console.debug(\n            `Retrying request on response status: ${response.status}`,\n            `Response: ${await response.text()}`,\n            `Attempt: ${attempts + 1}`,\n          );\n          // eslint-disable-next-line max-len\n          await new Promise((resolve) =>\n            setTimeout(resolve, Math.pow(2, (attempts + 1)) * 500),\n          );\n        } else {\n          throw new MistralAPIError(\n            `HTTP error! status: ${response.status} ` +\n            `Response: \\n${await response.text()}`,\n          );\n        }\n      } catch (error) {\n        console.error(`Request failed: ${error.message}`);\n        if (error.name === 'MistralAPIError') {\n          throw error;\n        }\n        if (attempts === this.maxRetries - 1) throw error;\n        // eslint-disable-next-line max-len\n        await new Promise((resolve) =>\n          setTimeout(resolve, Math.pow(2, (attempts + 1)) * 500),\n        );\n      }\n    }\n    throw new Error('Max retries reached');\n  };\n\n  /**\n   * Creates a chat completion request\n   * @param {*} model\n   * @param {*} messages\n   * @param {*} temperature\n   * @param {*} maxTokens\n   * @param {*} topP\n   * @param {*} randomSeed\n   * @param {*} stream\n   * @param {*} safeMode deprecated use safePrompt instead\n   * @param {*} safePrompt\n   * @return {Promise<Object>}\n   */\n  _makeChatCompletionRequest = function(\n    model,\n    messages,\n    temperature,\n    maxTokens,\n    topP,\n    randomSeed,\n    stream,\n    safeMode,\n    safePrompt,\n  ) {\n    return {\n      model: model,\n      messages: messages,\n      temperature: temperature ?? undefined,\n      max_tokens: maxTokens ?? undefined,\n      top_p: topP ?? undefined,\n      random_seed: randomSeed ?? undefined,\n      stream: stream ?? undefined,\n      safe_prompt: (safeMode || safePrompt) ?? undefined,\n    };\n  };\n\n  /**\n   * Returns a list of the available models\n   * @return {Promise<Object>}\n   */\n  listModels = async function() {\n    const response = await this._request('get', 'v1/models');\n    return response;\n  };\n\n  /**\n   * A chat endpoint without streaming\n   * @param {*} model the name of the model to chat with, e.g. mistral-tiny\n   * @param {*} messages an array of messages to chat with, e.g.\n   * [{role: 'user', content: 'What is the best French cheese?'}]\n   * @param {*} temperature the temperature to use for sampling, e.g. 0.5\n   * @param {*} maxTokens the maximum number of tokens to generate, e.g. 100\n   * @param {*} topP the cumulative probability of tokens to generate, e.g. 0.9\n   * @param {*} randomSeed the random seed to use for sampling, e.g. 42\n   * @param {*} safeMode deprecated use safePrompt instead\n   * @param {*} safePrompt whether to use safe mode, e.g. true\n   * @return {Promise<Object>}\n   */\n  chat = async function({\n    model,\n    messages,\n    temperature,\n    maxTokens,\n    topP,\n    randomSeed,\n    safeMode,\n    safePrompt,\n  }) {\n    const request = this._makeChatCompletionRequest(\n      model,\n      messages,\n      temperature,\n      maxTokens,\n      topP,\n      randomSeed,\n      false,\n      safeMode,\n      safePrompt,\n    );\n    const response = await this._request(\n      'post',\n      'v1/chat/completions',\n      request,\n    );\n    return response;\n  };\n\n  /**\n   * A chat endpoint that streams responses.\n   * @param {*} model the name of the model to chat with, e.g. mistral-tiny\n   * @param {*} messages an array of messages to chat with, e.g.\n   * [{role: 'user', content: 'What is the best French cheese?'}]\n   * @param {*} temperature the temperature to use for sampling, e.g. 0.5\n   * @param {*} maxTokens the maximum number of tokens to generate, e.g. 100\n   * @param {*} topP the cumulative probability of tokens to generate, e.g. 0.9\n   * @param {*} randomSeed the random seed to use for sampling, e.g. 42\n   * @param {*} safeMode deprecated use safePrompt instead\n   * @param {*} safePrompt whether to use safe mode, e.g. true\n   * @return {Promise<Object>}\n   */\n  chatStream = async function* ({\n    model,\n    messages,\n    temperature,\n    maxTokens,\n    topP,\n    randomSeed,\n    safeMode,\n    safePrompt,\n  }) {\n    const request = this._makeChatCompletionRequest(\n      model,\n      messages,\n      temperature,\n      maxTokens,\n      topP,\n      randomSeed,\n      true,\n      safeMode,\n      safePrompt,\n    );\n    const response = await this._request(\n      'post',\n      'v1/chat/completions',\n      request,\n    );\n\n    let buffer = '';\n    const decoder = new TextDecoder();\n    for await (const chunk of response) {\n      buffer += decoder.decode(chunk, {stream: true});\n      let firstNewline;\n      while ((firstNewline = buffer.indexOf('\\n')) !== -1) {\n        const chunkLine = buffer.substring(0, firstNewline);\n        buffer = buffer.substring(firstNewline + 1);\n        if (chunkLine.startsWith('data:')) {\n          const json = chunkLine.substring(6).trim();\n          if (json !== '[DONE]') {\n            yield JSON.parse(json);\n          }\n        }\n      }\n    }\n  };\n\n  /**\n   * An embeddings endpoint that returns embeddings for a single,\n   * or batch of inputs\n   * @param {*} model The embedding model to use, e.g. mistral-embed\n   * @param {*} input The input to embed,\n   * e.g. ['What is the best French cheese?']\n   * @return {Promise<Object>}\n   */\n  embeddings = async function({model, input}) {\n    const request = {\n      model: model,\n      input: input,\n    };\n    const response = await this._request('post', 'v1/embeddings', request);\n    return response;\n  };\n}\n\nexport default MistralClient;\n"],
  "mappings": ";;;;;AAAA,IAAI,SAAS;AAEb,IAAM,UAAU;AAChB,IAAM,qBAAqB,CAAC,KAAK,KAAK,KAAK,KAAK,GAAG;AACnD,IAAM,WAAW;AAMjB,eAAe,kBAAkB;AAC/B,MAAI,OAAO,WAAW,eACpB,OAAO,WAAW,UAAU,aAAa;AACzC,UAAM,YAAY,MAAM,OAAO,mBAAY;AAC3C,YAAQ,UAAU;AAClB,aAAS;AAAA,EACX,OAAO;AACL,YAAQ,WAAW;AAAA,EACrB;AACF;AAEA,gBAAgB;AAOhB,IAAM,kBAAN,cAA8B,MAAM;AAAA;AAAA;AAAA;AAAA;AAAA,EAKlC,YAAY,SAAS;AACnB,UAAM,OAAO;AACb,SAAK,OAAO;AAAA,EACd;AACF;AAMA,IAAM,gBAAN,MAAoB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASlB,YACE,SAAS,QAAQ,IAAI,iBACrB,WAAW,UACX,aAAa,GACb,UAAU,KACV;AAeF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oCAAW,eAAe,QAAQ,MAAM,SAAS;AAC/C,YAAM,MAAM,GAAG,KAAK,QAAQ,IAAI,IAAI;AACpC,YAAM,UAAU;AAAA,QACd;AAAA,QACA,SAAS;AAAA,UACP,cAAc,qBAAqB,OAAO;AAAA,UAC1C,WAAU,mCAAS,UAAS,sBAAsB;AAAA,UAClD,gBAAgB;AAAA,UAChB,iBAAiB,UAAU,KAAK,MAAM;AAAA,QACxC;AAAA,QACA,MAAM,WAAW,QAAQ,KAAK,UAAU,OAAO,IAAI;AAAA,QACnD,SAAS,KAAK,UAAU;AAAA,MAC1B;AAEA,eAAS,WAAW,GAAG,WAAW,KAAK,YAAY,YAAY;AAC7D,YAAI;AACF,gBAAM,WAAW,MAAM,MAAM,KAAK,OAAO;AAEzC,cAAI,SAAS,IAAI;AACf,gBAAI,mCAAS,QAAQ;AACnB,kBAAI,QAAQ;AACV,uBAAO,SAAS;AAAA,cAClB,OAAO;AACL,sBAAM,SAAS,SAAS,KAAK,UAAU;AAEvC,sBAAM,gBAAgB,mBAAmB;AACvC,sBAAI;AACF,2BAAO,MAAM;AAEX,4BAAM,EAAC,MAAM,MAAK,IAAI,MAAM,OAAO,KAAK;AAExC,0BAAI;AAAM;AAEV,4BAAM;AAAA,oBACR;AAAA,kBACF,UAAE;AACA,2BAAO,YAAY;AAAA,kBACrB;AAAA,gBACF;AAEA,uBAAO,cAAc;AAAA,cACvB;AAAA,YACF;AACA,mBAAO,MAAM,SAAS,KAAK;AAAA,UAC7B,WAAW,mBAAmB,SAAS,SAAS,MAAM,GAAG;AACvD,oBAAQ;AAAA,cACN,wCAAwC,SAAS,MAAM;AAAA,cACvD,aAAa,MAAM,SAAS,KAAK,CAAC;AAAA,cAClC,YAAY,WAAW,CAAC;AAAA,YAC1B;AAEA,kBAAM,IAAI;AAAA,cAAQ,CAAC,YACjB,WAAW,SAAS,KAAK,IAAI,GAAI,WAAW,CAAE,IAAI,GAAG;AAAA,YACvD;AAAA,UACF,OAAO;AACL,kBAAM,IAAI;AAAA,cACR,uBAAuB,SAAS,MAAM;AAAA,EACvB,MAAM,SAAS,KAAK,CAAC;AAAA,YACtC;AAAA,UACF;AAAA,QACF,SAAS,OAAO;AACd,kBAAQ,MAAM,mBAAmB,MAAM,OAAO,EAAE;AAChD,cAAI,MAAM,SAAS,mBAAmB;AACpC,kBAAM;AAAA,UACR;AACA,cAAI,aAAa,KAAK,aAAa;AAAG,kBAAM;AAE5C,gBAAM,IAAI;AAAA,YAAQ,CAAC,YACjB,WAAW,SAAS,KAAK,IAAI,GAAI,WAAW,CAAE,IAAI,GAAG;AAAA,UACvD;AAAA,QACF;AAAA,MACF;AACA,YAAM,IAAI,MAAM,qBAAqB;AAAA,IACvC;AAeA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sDAA6B,SAC3B,OACA,UACA,aACA,WACA,MACA,YACA,QACA,UACA,YACA;AACA,aAAO;AAAA,QACL;AAAA,QACA;AAAA,QACA,aAAa,eAAe;AAAA,QAC5B,YAAY,aAAa;AAAA,QACzB,OAAO,QAAQ;AAAA,QACf,aAAa,cAAc;AAAA,QAC3B,QAAQ,UAAU;AAAA,QAClB,cAAc,YAAY,eAAe;AAAA,MAC3C;AAAA,IACF;AAMA;AAAA;AAAA;AAAA;AAAA,sCAAa,iBAAiB;AAC5B,YAAM,WAAW,MAAM,KAAK,SAAS,OAAO,WAAW;AACvD,aAAO;AAAA,IACT;AAeA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gCAAO,eAAe;AAAA,MACpB;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF,GAAG;AACD,YAAM,UAAU,KAAK;AAAA,QACnB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACF;AACA,YAAM,WAAW,MAAM,KAAK;AAAA,QAC1B;AAAA,QACA;AAAA,QACA;AAAA,MACF;AACA,aAAO;AAAA,IACT;AAeA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sCAAa,iBAAiB;AAAA,MAC5B;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF,GAAG;AACD,YAAM,UAAU,KAAK;AAAA,QACnB;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACF;AACA,YAAM,WAAW,MAAM,KAAK;AAAA,QAC1B;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAEA,UAAI,SAAS;AACb,YAAM,UAAU,IAAI,YAAY;AAChC,uBAAiB,SAAS,UAAU;AAClC,kBAAU,QAAQ,OAAO,OAAO,EAAC,QAAQ,KAAI,CAAC;AAC9C,YAAI;AACJ,gBAAQ,eAAe,OAAO,QAAQ,IAAI,OAAO,IAAI;AACnD,gBAAM,YAAY,OAAO,UAAU,GAAG,YAAY;AAClD,mBAAS,OAAO,UAAU,eAAe,CAAC;AAC1C,cAAI,UAAU,WAAW,OAAO,GAAG;AACjC,kBAAM,OAAO,UAAU,UAAU,CAAC,EAAE,KAAK;AACzC,gBAAI,SAAS,UAAU;AACrB,oBAAM,KAAK,MAAM,IAAI;AAAA,YACvB;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAUA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sCAAa,eAAe,EAAC,OAAO,MAAK,GAAG;AAC1C,YAAM,UAAU;AAAA,QACd;AAAA,QACA;AAAA,MACF;AACA,YAAM,WAAW,MAAM,KAAK,SAAS,QAAQ,iBAAiB,OAAO;AACrE,aAAO;AAAA,IACT;AAzPE,SAAK,WAAW;AAChB,SAAK,SAAS;AAEd,SAAK,aAAa;AAClB,SAAK,UAAU;AAAA,EACjB;AAqPF;AAEA,IAAO,iBAAQ;",
  "names": []
}
